# -*- coding: utf-8 -*-
"""Welcome To Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/notebooks/intro.ipynb
"""

#pip install transformers
from transformers import pipeline
import random
import os
from urllib.request import urlopen
import json

summarizer = pipeline("summarization", model="t5-base", tokenizer="t5-base", framework="tf")
sentiment_pipeline = pipeline("sentiment-analysis", model="ProsusAI/finbert", tokenizer="ProsusAI/finbert")

heading_map_10K = {
    "Item 1": "Business",
    "Item 1A": "Risk Factors",
    "Item 1B": "Unresolved Staff Comments",
    "Item 2": "Properties",
    "Item 3": "Legal Proceedings",
    "Item 4": "Mine Safety Disclosures",
    "Item 5": "Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities",
    "Item 6": "Reserved",
    "Item 7": "Management’s Discussion and Analysis of Financial Condition and Results of Operations",
    "Item 7A": "Quantitative and Qualitative Disclosures About Market Risk",
    "Item 8": "Financial Statements and Supplementary Data",
    "Item 9": "Changes in and Disagreements with Accountants on Accounting and Financial Disclosure",
    "Item 9A": "Controls and Procedures",
    "Item 9B": "Other Information",
    "Item 9C": "Disclosure Regarding Foreign Jurisdictions that Prevent Inspections",
    "Item 10": "Directors, Executive Officers and Corporate Governance",
    "Item 11": "Executive Compensation",
    "Item 12": "Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters",
    "Item 13": "Certain Relationships and Related Transactions, and Director Independence",
    "Item 14": "Principal Accounting Fees and Services",
    "Item 15": "Exhibits, Financial Statement Schedules"
}

url = "https://raw.githubusercontent.com/gajrajgchouhan/Extract_CIK/main/data/fillings.json?token=GHSAT0AAAAAABHPSZWCL2AFBRAQDPNBWZK6YR4IL3Q"
response = urlopen(url)
data = json.loads(response.read())

print("Data Read from Gitub")

summarized_data = []

for company in data:
	for fillings in company["fillings"]:
		final_data = {}
		final_data["cik"] = company["cik"]
		final_data["paras"] = []
		asn = fillings["asn"]
		final_data["asn"] = asn.split("-")[1]
		key_list = list(fillings["parsed"].keys())
		item_no = 0
		for item in fillings["parsed"]:
			item_no+=1
			item_text = fillings["parsed"][item]
			text = ' '.join(item_text)
			text.replace('\n',' ')
			print(item_no, len(text))
			if(len(text)>10000):
				summary_text = summarizer(text, max_length=100, min_length=5, do_sample=False)[0]['summary_text']
				sentiment_data = [summary_text]
				scores = sentiment_pipeline(sentiment_data, return_all_scores=True)
				positive_sentiment_score = scores[0][0]['score']
				heading = heading_map_10K[key_list[item_no]]
				final_dict = {"heading":"", "content":"", "sentiment":""}
				final_dict["heading"] = heading
				final_dict["content"] = summary_text
				final_dict["sentiment"] = positive_sentiment_score
				print(final_dict)
				final_data["paras"].append(final_dict)
		summarized_data.append(final_data)
print(summarized_data)
json_object = json.dumps(summarized_data, indent = 4) 
print(json_object)
with open("sample.json", "w") as outfile:
	json.dump(json_object, outfile)
